{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an awk function to select the gene id and first transcript of each gene\n",
    "#figure out which column numbers are geneid and transcript in\n",
    "#select the transcripts of the file only\n",
    "awk '$3== \"transcript\"' stringtie_merged.gtf > StrTranscript_list.txt\n",
    "\n",
    "# work on the first few lines\n",
    "nawk -F, '{if(NR<=10) {print$1}}' StrTranscript_list.txt\n",
    "\n",
    "#select the gene id's and the transcript id's from the txt using awk column select | get rid of the \" ; so that only the id's are left\n",
    "awk '{print $10\"\\t\"$12}' StrTranscript_list.txt | sed 's/\"//g;s/;//g'^C\n",
    "sed -i 's/\\t/,/g' replaced.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# download txt as a dataframe \n",
    "table = pd.read_csv('/RNA/VALENCIA/replaced.txt', sep=\",\", header=None)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column names of the dataframes and save as csv\n",
    "table.columns = ['geneID','trID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort the gene id's and select the unique values\n",
    "table = table.drop_duplicates(subset='geneID')\n",
    "table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#1) use gffread to extract the transcript sequences\n",
    "# -w writes the fasta file for exons for each transcript, -g directs the path to the fasta file being used\n",
    "gffread -w transcripts.fa -g /RNA/VALENCIA/csi.chromosome.fa stringtie_merged.gtf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#2)create a blastdb using the newly created fastafile\n",
    "#creating a masked database to protect the original fasta file\n",
    "dustmasker -in transcripts.fa -infmt fasta -parse_seqids -outfmt maskinfo_asn1_bin -out transcript_dust.asnb\n",
    "\n",
    "#create a database from the maseked file\n",
    "makeblastdb -in transcripts.fa -input_type fasta -dbtype nucl -parse_seqids -mask_data transcript_dust.asnb -out mask_transcripts.fa -title \"Citrus Sinesis Chr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) output all the genes' frst transcript sequences using blastdbcmd\n",
    "# ~in jupyter~ output the 2nd column of transcript ID's as a list/txt file\n",
    "table['transcriptID'].to_csv('/RNA/VALENCIA/table.txt', index = False, header = False )\n",
    "\n",
    "# create the blastdatabse by referencing the list/txt file created from python\n",
    "blastdbcmd -entry_batch table.txt -db /RNA/VALENCIA/mask_transcripts.fa -outfmt \"%f\" -out csi_blast.fa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#4) create a blastdb using the clementine genes\n",
    "# download the transcripts and the annotated exons so that you may create a fasta file that can be read\n",
    "wget ftp://ftp.bioinfo.wsu.edu/species/Citrus_clementina/C.clementina_JGI_v1.0_genome/assembly/Cclementina_182_v1.fa\n",
    "ftp://ftp.bioinfo.wsu.edu/species/Citrus_clementina/C.clementina_JGI_v1.0_genome/annotation/Cclementina_182_v1.0.gene_exons.gff3^C\n",
    "\n",
    "#rename the files using the mv function to ccl.chromosome.fa ccl.gene_exons.gff3 \n",
    "# recreate the fasta index because the installed one is outdated. \n",
    "samtools faidx ccl.chromosome.fa \n",
    "\n",
    "# use gffread to change gff3 format into gtf format\n",
    "gffread -E ccl.genes_exons.gff3 -T -o ccl.genes_exons.gtf\n",
    "# use gffread to output the exon transcript sequences\n",
    "gffread ccl.gene_exons.gtf -w ccl.transcripts.fa -g /RNA/VALENCIA/ccl.chromosome.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)create a blastdb using the newly created fastafile\n",
    "#creating a masked database to protect the original fasta file\n",
    "dustmasker -in ccl.transcripts.fa -infmt fasta -parse_seqids -outfmt maskinfo_asn1_bin -out ccl.transcript_dust.asnb\n",
    "\n",
    "#create a database from the maseked file\n",
    "makeblastdb -in ccl.transcripts.fa -input_type fasta -dbtype nucl -parse_seqids -mask_data ccl.transcript_dust.asnb -out mask_ccl.transcripts.fa -title \"Citrus Clementine Chr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) blastn the csi sequence to the clementine database genes\n",
    "blastn -db /RNA/VALENCIA/mask_ccl.transcripts.fa -query csi_blast.fa -outfmt 7 -out results.out\n",
    "\n",
    "# filter the blast with >90% identity, alignment_length>100bp, \n",
    "blastn -db /RNA/VALENCIA/mask_ccl.transcripts.fa -query csi_blast.fa -num_threads 12 -outfmt 6 -out results.out\n",
    "\n",
    "# column names\n",
    "query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) export the results to pandas df so that it can filtered with 90% identity, alignment_length>100bp and the best bitscore\n",
    "results = pd.read_csv('/RNA/VALENCIA/results.out', sep = '\\t', header = None)\n",
    "results.columns = ['query','subject','% identity','length','mismatches','gaps','q.start','q.end','s.start','s.end','eval','bit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the results\n",
    "filter_res = results.loc[(results['% identity']>=90) & (results['length']>=100)] \n",
    "# drop duplicates\n",
    "filter_res = filter_res.drop_duplicates(subset='query')\n",
    "filter_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export as csv\n",
    "filter_res.to_csv('/RNA/VALENCIA/filter_res.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# match the id's found in upregGHA_PFA with the id's created frome filter_results\n",
    "# import the files as dataframes\n",
    "df = pd.read_csv('/RNA/VALENCIA/test.txt', sep ='\\t', header = None)\n",
    "df.columns = ['trID','subjID']\n",
    "ghalist = pd.read_csv('/RNA/quants/upregGHA_PFA.csv')\n",
    "ghalist.columns = ['geneID', 'log2FC', 'pval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge = df.merge(table, on='trID', how='inner')\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = merge.merge(ghalist, on='geneID', how='inner')\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the subjID to match the required ID for AgriGO\n",
    "list['subjID'] = list['subjID'].str.replace('\\.v1.0','.g')\n",
    "list['subjID'].to_csv('/RNA/VALENCIA/list.txt', index = False, header = False)\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the downregGHA_PFA genes\n",
    "df = pd.read_csv('/RNA/VALENCIA/test.txt', sep ='\\t', header = None)\n",
    "df.columns = ['trID','subjID']\n",
    "ghalist = pd.read_csv('/RNA/quants/downregGHA_PFA.csv')\n",
    "ghalist.columns = ['geneID', 'log2FC', 'pval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = df.merge(table, on='trID', how='inner')\n",
    "list = merge.merge(ghalist, on='geneID', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the subjID to match the required ID for AgriGO and output\n",
    "list['subjID'] = list['subjID'].str.replace('\\.v1.0','.g')\n",
    "list['subjID'].to_csv('/RNA/VALENCIA/list.txt', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat for all other compressions\n",
    "df = pd.read_csv('/RNA/VALENCIA/test.txt', sep ='\\t', header = None)\n",
    "df.columns = ['trID','subjID']\n",
    "ghalist = pd.read_csv('/RNA/quants/upreg108_PV5.csv')\n",
    "ghalist.columns = ['geneID', 'log2FC', 'pval']\n",
    "\n",
    "ghalistdown = pd.read_csv('/RNA/quants/downreg108_PV5.csv')\n",
    "ghalistdown.columns = ['geneID', 'log2FC', 'pval']\n",
    "\n",
    "list = merge.merge(ghalist, on='geneID', how='inner')\n",
    "listdown = merge.merge(ghalistdown, on='geneID', how='inner')\n",
    "\n",
    "# change the subjID to match the required ID for AgriGO and output\n",
    "list['subjID'] = list['subjID'].str.replace('\\.v1.0','.g')\n",
    "list['subjID'].to_csv('/RNA/VALENCIA/list.txt', index = False, header = False)\n",
    "\n",
    "listdown['subjID'] = listdown['subjID'].str.replace('\\.v1.0','.g')\n",
    "listdown['subjID'].to_csv('/RNA/VALENCIA/listdown.txt', index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
